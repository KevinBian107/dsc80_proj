{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: The Data Science Lifecycle üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Project 4, the final assignment of the quarter! üëã\n",
    "\n",
    "This project aims to be a culmination of everything you‚Äôve learned this quarter. In Project 4, you will conduct **an open-ended investigation** into one of the three datasets (Recipes and Ratings üçΩ, League of Legends ‚å®Ô∏è, or Power Outages üîã). Specifically, you‚Äôll **draw several visualizations** to help understand the distributions of key variables, **assess the missingness mechanisms** of columns with missing values, **test a hypotheses about the data**, and finally, **build and improve a predictive model**. This project will be entirely manually graded by us ‚Äì that‚Äôs right, no autograders!\n",
    "\n",
    "Project 4 is worth 10% in your overall grade, which means it‚Äôs worth double what previous projects were worth. Its checkpoint is also worth double a regular checkpoint, at 2%. You should think of Project 4 like a ‚ÄúFinal Project.‚Äù\n",
    "\n",
    "As your final deliverables, you‚Äôll submit two things to us: a public-facing website as well as a PDF of your Jupyter Notebook. We encourage you to build something you are proud of as this will give you something concrete to put on your resume and show to potential employers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Catalog:\n",
    "Visit Instruction at https://dsc80.com/proj04/#step-1-introduction\n",
    "\n",
    "The project is broken into two parts:\n",
    "\n",
    "1. Part 1: **An analysis**, submitted as a Jupyter Notebook. This will contain the details of your work. Focus on completing your analysis before moving to Part 2, as the analysis is the bulk of the project.\n",
    "\n",
    "2. Part 2: **A report**, submitted as a website. This will contain a narrative ‚Äústory‚Äù with visuals. Focus on this after finishing most of your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choosing a Dataset\n",
    "2. Part 1.1: Analysis of Data\n",
    "    - Step 1: Introduction\n",
    "    - Step 2: Data Cleaning and Exploratory Data Analysis\n",
    "    - Step 3: Assessment of Missingness\n",
    "    - Step 4: Hypothesis Testing\n",
    "3. Part 1.2: Predictive Model\n",
    "    - Step 5: Framing a Prediction Problem\n",
    "    - Step 6: Baseline Model\n",
    "    - Step 7: Final Model\n",
    "    - Step 8: Fairness Analysis\n",
    "    - Style\n",
    "4. Part 2: Report\n",
    "    - Step 1: Initializing a Jekyll GitHub Pages Site\n",
    "    - Step 2: Choosing a Theme\n",
    "    - Step 3: Embedding Content\n",
    "    - Local Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Dataset\n",
    "In this project, you will perform an open-ended investigation into a single dataset. You must choose one of the following three datasets.\n",
    "\n",
    "1. Recipes and Ratings üçΩ\n",
    "2. League of Legends ‚å®Ô∏è\n",
    "3. Power Outages üîã\n",
    "\n",
    "The dataset description pages linked above each have three sections:\n",
    "\n",
    "1. Getting the Data: Describes how to access the data and, in some cases, what various features mean. (In general, you‚Äôre going to have to understand what your data means on your own!)\n",
    "\n",
    "2. Example Questions and Prediction Problems: Example questions to explore in Part 1: Steps 1-4, and example prediction problems to build models for in Part 1: Steps 5-8. Use these as inspiration, but feel free to come up with your own questions and prediction problems!\n",
    "\n",
    "3. Special Considerations: Things to be aware of when working with the given dataset, e.g. some additional requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Analysis\n",
    "Before beginning your analysis, you‚Äôll need to set up a few things.\n",
    "\n",
    "1. Pull the latest version of the dsc80-2024-wi repo. Within the projects/proj04 folder, there is a template.ipynb notebook that you will use as a template for the project. If you delete the file or want another copy of the template, you can re-download it from here. This is where your analysis will live; you will submit this entire notebook to us.\n",
    "\n",
    "2. Select one of the three datasets mentioned above, download it, and load it into your template notebook.\n",
    "\n",
    "Once you have your dataset loaded in your notebook, it‚Äôs time for you to find meaning in the real-world data you‚Äôve collected! Follow the steps below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction\n",
    "**Analysis**:\n",
    "1. Understand the data you have access to.\n",
    "2. Brainstorm a few questions that interest you about the dataset.\n",
    "3. Pick one question you plan to investigate further. (As the data science lifecycle tells us, this question may change as you work on your project.)\n",
    "\n",
    "**Report**:\n",
    "Provide an introduction to your dataset, and clearly state the one question your project is centered around. Why should readers of your website care about the dataset and your question specifically? Report the number of rows in the dataset, the names of the columns that are relevant to your question, and descriptions of those relevant columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis\n",
    "### Data Cleaning:\n",
    "**Analysis**:\n",
    "Clean the data appropriately. For instance, you may need to replace data that should be missing with NaN or create new columns out of given ones (e.g. compute distances, scale data, or get time information from time stamps).\n",
    "\n",
    "**Report**:\n",
    "Describe, in detail, the data cleaning steps you took and how they affected your analyses. The steps should be explained in reference to the data generating process. Show the head of your cleaned DataFrame (see Part 2: Report for instructions).\n",
    "\n",
    "### Univariate Analysis:\n",
    "**Analysis**:\n",
    "Look at the distributions of relevant columns separately by using DataFrame operations and drawing at least two relevant plots.\n",
    "\n",
    "**Report**:\n",
    "Embed at least one plotly plot you created in your notebook that displays the distribution of a single column (see Part 2: Report for instructions). Include a 1-2 sentence explanation about your plot, making sure to describe and interpret any trends present. (Your notebook will likely have more visualizations than your website, and that‚Äôs fine. Feel free to embed more than one univariate visualization in your website if you‚Äôd like, but make sure that each embedded plot is accompanied by a description.)\n",
    "\n",
    "### Bivariate Analysis:\n",
    "**Analysis**:\n",
    "Look at the statistics of pairs of columns to identify possible associations. For instance, you may create scatter plots and plot conditional distributions, or box-plots. You must plot at least two such plots in your notebook. The results of your bivariate analyses will be helpful in identifying interesting hypothesis tests!\n",
    "\n",
    "**Report**:\n",
    "Embed at least one plotly plot that displays the relationship between two columns. Include a 1-2 sentence explanation about your plot, making sure to describe and interpret any trends present. (Your notebook will likely have more visualizations than your website, and that‚Äôs fine. Feel free to embed more than one bivariate visualization in your website if you‚Äôd like, but make sure that each embedded plot is accompanied by a description.)\n",
    "\n",
    "### Interesting Aggregates:\n",
    "**Analysis**:\n",
    "Choose columns to group and pivot by and examine aggregate statistics.\n",
    "\n",
    "**Report**:\n",
    "Embed at least one grouped table or pivot table in your website and explain its significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assessment of Missingness\n",
    "### NMAR Analysis\n",
    "**Analysis**:\n",
    "Recall, to determine whether data are likely NMAR, you must reason about the data generating process; you cannot conclude that data are likely NMAR solely by looking at your data. As such, there‚Äôs no code to write here (and hence, nothing to put in your notebook).\n",
    "\n",
    "**Report**:\n",
    "State whether you believe there is a column in your dataset that is NMAR. Explain your reasoning and any additional data you might want to obtain that could explain the missingness (thereby making it MAR). Make sure to explicitly use the term ‚ÄúNMAR.‚Äù\n",
    "\n",
    "### Missingness Dependency\n",
    "**Analysis**:\n",
    "Pick a column in the dataset with non-trivial missingness to analyze, and perform permutation tests to analyze the dependency of the missingness of this column on other columns.\n",
    "\n",
    "Specifically, find at least one other column that the missingness of your selected column does depend on, and at least one other column that the missingness of your selected column does not depend on.\n",
    "\n",
    "Tip: Make sure you know the difference between the different types of missingness before approaching that section. Many students in the past have lost credit for mistaking one type of missingness for another.\n",
    "\n",
    "Note that some datasets may have special requirements for this section; look at the ‚ÄúSpecial Considerations‚Äù section of your chosen dataset for more details.\n",
    "\n",
    "**Report**:\n",
    "Present and interpret the results of your missingness permutation tests with respect to your data and question. Embed a plotly plot related to your missingness exploration; ideas include:\n",
    "‚Ä¢ The distribution of column Y when column X is missing and the distribution of column Y when column X is not missing, as was done in Lecture 8.\n",
    "‚Ä¢ The empirical distribution of the test statistic used in one of your permutation tests, along with the observed statistic.\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hypothesis Testing\n",
    "**Analysis**:\n",
    "Clearly state a pair of hypotheses and perform a hypothesis test or permutation test that is not related to missingness. Feel free to use one of the example questions stated in the ‚ÄúExample Questions and Prediction Problems‚Äù section of your dataset‚Äôs description page or pose a hypothesis test of your own.\n",
    "\n",
    "**Report**:\n",
    "Clearly state your null and alternative hypotheses, your choice of test statistic and significance level, the resulting p-value, and your conclusion. Justify why these choices are good choices for answering the question you are trying to answer.\n",
    "\n",
    "Optional: Embed a visualization related to your hypothesis test in your website.\n",
    "\n",
    "Tip: When making writing your conclusions to the statistical tests in this project, never use language that implies an absolute conclusion; since we are performing statistical tests and not randomized controlled trials, we cannot prove that either hypothesis is 100% true or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Framing a Prediction Problem\n",
    "### Problem Identification\n",
    "**Analysis**:\n",
    "Identify a prediction problem. Feel free to use one of the example prediction problems stated in the ‚ÄúExample Questions and Prediction Problems‚Äù section of your dataset‚Äôs description page or pose a hypothesis test of your own. The prediction problem you come up with doesn‚Äôt have to be related to the question you were answering in Steps 1-4, but ideally, your entire project has some sort of coherent theme.\n",
    "\n",
    "**Report**:\n",
    "Clearly state your prediction problem and type (classification or regression). If you are building a classifier, make sure to state whether you are performing binary classification or multiclass classification. Report the response variable (i.e. the variable you are predicting) and why you chose it, the metric you are using to evaluate your model and why you chose it over other suitable metrics (e.g. accuracy vs. F1-score).\n",
    "\n",
    "Note: Make sure to justify what information you would know at the ‚Äútime of prediction‚Äù and to only train your model using those features. For instance, if we wanted to predict your final exam grade, we couldn‚Äôt use your Project 4 grade, because Project 4 is only due after the final exam! Feel free to ask questions if you‚Äôre not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Model\n",
    "### Baseline Model\n",
    "**Analysis**:\n",
    "Train a ‚Äúbaseline model‚Äù for your prediction task that uses at least two features. (For this requirement, two features means selecting at least two columns from your original dataset that you should transform). You can leave numerical features as-is, but you‚Äôll need to take care of categorical columns using an appropriate encoding. Implement all steps (feature transforms and model training) in a single sklearn Pipeline.\n",
    "\n",
    "Note: Both now and in Step 7: Final Model, make sure to evaluate your model‚Äôs ability to generalize to unseen data!\n",
    "\n",
    "There is no ‚Äúrequired‚Äù performance metric that your baseline model needs to achieve.\n",
    "\n",
    "**Report**:\n",
    "Describe your model and state the features in your model, including how many are quantitative, ordinal, and nominal, and how you performed any necessary encodings. Report the performance of your model and whether or not you believe your current model is ‚Äúgood‚Äù and why.\n",
    "\n",
    "Tip: Make sure to hit all of the points above: many projects in the past have lost points for not doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Model\n",
    "### Final Model\n",
    "**Analysis**:\n",
    "Create a ‚Äúfinal‚Äù model that improves upon the ‚Äúbaseline‚Äù model you created in Step 2. Do so by engineering at least two new features from the data, on top of any categorical encodings you performed in Baseline Model Step. (For instance, you may use a StandardScaler on a quantitative column and a QuantileTransformer transformer on a different column to get two new features.) Again, implement all steps in a single sklearn Pipeline. While deciding what features to use, you must perform a search for the best hyperparameters (e.g. tree depth) to use amongst a list(s) of options, either by using GridSearchCV or through some manual iterative method. In your notebook, state which hyperparameters you plan to tune and why before actually tuning them.\n",
    "\n",
    "- Optional: You are encouraged to try many different modeling algorithms for your final model (i.e. LinearRegression, RandomForestClassifier, Lasso, SVC, etc.) If you do this, make sure to clearly indicate in your notebook which model is your actual final model as that will be used to grade the above requirements.\n",
    "\n",
    "- Note 1: When training your model, make sure you use the same unseen and seen datasets from your baseline model. This way, the evaluation metric you get on your final model can be compared to your baseline‚Äôs on the basis of the model itself and not the dataset it was trained on. Based on which method you use for hyperparameter tuning, this may mean that you will need to use some of your training data as your validation data. If this is the case, make sure to train your final model on the whole dataset prior to evaluation.\n",
    "\n",
    "- Note 2: You will not be graded on ‚Äúhow much‚Äù your model improved from Step 6: Baseline Model to Step 7: Final Model. What you will be graded on is on whether or not your model improved, as well as your thoughtfulness and effort in creating features, along with the other points above.\n",
    "\n",
    "- Note 3: Don‚Äôt try to improve your model‚Äôs performance just by blindly transforming existing features into new ones. Think critically about what each transformation you‚Äôre doing actually does. For example, there‚Äôs no use in using a StandardScaler transformer if your goal is to reduce the RMSE of a linear model: as we learned in DSC 40A, and in Lecture 15, standardizing features in a regression model does not change the model‚Äôs predictions, only its coefficients!\n",
    "\n",
    "**Report**:\n",
    "State the features you added and why they are good for the data and prediction task. Note that you can‚Äôt simply state ‚Äúthese features improved my accuracy‚Äù, since you‚Äôd need to choose these features and fit a model before noticing that ‚Äì instead, talk about why you believe these features improved your model‚Äôs performance from the perspective of the data generating process.\n",
    "\n",
    "Describe the modeling algorithm you chose, the hyperparameters that ended up performing the best, and the method you used to select hyperparameters and your overall model. Describe how your Final Model‚Äôs performance is an improvement over your Baseline Model‚Äôs performance.\n",
    "\n",
    "Optional: Include a visualization that describes your model‚Äôs performance, e.g. a confusion matrix, if applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fairness Analysis\n",
    "### Fairness Analysis\n",
    "**Analysis**:\n",
    "Perform a ‚Äúfairness analysis‚Äù of your Final Model from the previous step. That is, try and answer the question ‚Äúdoes my model perform worse for individuals in Group X than it does for individuals in Group Y?‚Äù, for an interesting choice of X and Y.\n",
    "\n",
    "As always, when comparing some quantitative attribute (in this case, something like precision or RMSE) across two groups, we use a permutation test. Let‚Äôs illustrate how this works with an example. Let‚Äôs suppose we have a sample voter dataset with columns 'Name', 'Age', and 'Voted', among others. We build a classifier that predicts whether someone voted (1) or didn‚Äôt (0).\n",
    "\n",
    "Here, we‚Äôll say our two groups are\n",
    "- ‚Äúyoung people‚Äù, people younger than 40\n",
    "- ‚Äúold people‚Äù, people older than 40\n",
    "\n",
    "Note that in this example, we manually created these groups by binarizing the 'Age' column in our dataset, and that‚Äôs fine. (Remember, the Binarizer transformer with a threshold of 40 can do this for us.)\n",
    "\n",
    "For our evaluation metric, we‚Äôll choose precision. (In Week 10‚Äôs lectures, we‚Äôll look at other evaluation metrics and related parity measures for classifiers; choose the one that is most appropriate to your prediction task. If you built a regression model, you cannot use classification metrics like precision or recall; instead, you must use RMSE or R2.)\n",
    "\n",
    "Now, we must perform a permutation test. Before doing so, we must clearly state a null and an alternative hypothesis.\n",
    "\n",
    "- Null Hypothesis: Our model is fair. Its precision for young people and old people are roughly the same, and any differences are due to random chance.\n",
    "- Alternative Hypothesis: Our model is unfair. Its precision for young people is lower than its precision for old people.\n",
    "\n",
    "From here, you should be able to implement the necessary permutation test. The only other guidance we will provide you with is that you should not be modifying your model to produce different results when computing test statistics; use only your final fitted model from Final Model Step.\n",
    "\n",
    "**Report**:\n",
    "Clearly state your choice of Group X and Group Y, your evaluation metric, your null and alternative hypotheses, your choice of test statistic and significance level, the resulting p-value, and your conclusion.\n",
    "\n",
    "Optional: Embed a visualization related to your permutation test in your website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style\n",
    "While your website will neatly organized and tailored for public consumption, it is important to keep your analysis notebook organized as well. Follow these guidelines:\n",
    "\n",
    "- Your work for each of the eight project steps described above (Introduction, Data Cleaning and Exploratory Data Analysis, ‚Ä¶, Fairness Analysis) should be completed in code cells underneath the Markdown header of that section‚Äôs name.\n",
    "\n",
    "- You should only include work that is relevant to posing, explaining, and answering the question(s) you state in your website. You should include data quality, cleaning, and missingness assessments, and intermediate models and features you tried, though these should broadly be relevant to the tasks at hand.\n",
    "\n",
    "- Make sure to clearly explain what each component of your notebook means. Specifically:\n",
    "All plots should have titles, labels, and a legend (if applicable), even if they don‚Äôt make it into your website. Plots should be self-contained ‚Äì readers should be able to understand what they describe without having to read anything else.\n",
    "\n",
    "- All code cells should contain a comment describing how the code works (unless the code is self-explanatory ‚Äì use your best judgement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
