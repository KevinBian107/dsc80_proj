{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framing Prediction Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "from itertools import chain\n",
    "\n",
    "from utils.eda import *\n",
    "from utils.dsc80_utils import *\n",
    "from utils.graph import *\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.read_csv('food_data/RAW_interactions.csv')\n",
    "recipes = pd.read_csv('food_data/RAW_recipes.csv')\n",
    "step0 = recipes.merge(interactions, how='left', left_on='id', right_on='recipe_id', indicator=True)\n",
    "df_recipe = (step0\n",
    "      .pipe(initial)\n",
    "      .pipe(transform_df)\n",
    "      #.pipe(outlier)\n",
    "      .pipe(group_recipe)\n",
    "      #.pipe(group_user)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Identification\n",
    "**Analysis**:\n",
    "Identify a prediction problem. Feel free to use one of the example prediction problems stated in the “Example Questions and Prediction Problems” section of your dataset’s description page or pose a hypothesis test of your own. The prediction problem you come up with doesn’t have to be related to the question you were answering in Steps 1-4, but ideally, your entire project has some sort of coherent theme.\n",
    "\n",
    "**Report**:\n",
    "Clearly state your prediction problem and type (classification or regression). If you are building a classifier, make sure to state whether you are performing binary classification or multiclass classification. Report the response variable (i.e. the variable you are predicting) and why you chose it, the metric you are using to evaluate your model and why you chose it over other suitable metrics (e.g. accuracy vs. F1-score).\n",
    "\n",
    "Note: Make sure to justify what information you would know at the “time of prediction” and to only train your model using those features. For instance, if we wanted to predict your final exam grade, we couldn’t use your Project 4 grade, because Project 4 is only due after the final exam! Feel free to ask questions if you’re not sure.\n",
    "\n",
    "### Some Potential Ideas:\n",
    "1. Sentiment Analysis with `review` column\n",
    "2. Using   `recipe` column and feature engineering (length of `recipe`, TF-IDF, ...) to predict `ratings`\n",
    "3. Using text data as a input to predict the rating of the user and identify preference of users (pre-step to reconmender system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['minutes', 'n_steps', 'n_ingredients', 'avg_rating', 'rating',\n",
       "       'calories', 'total_fat', 'sugar', 'sodium', 'protein', 'sat_fat',\n",
       "       'carbs', 'steps', 'name', 'description', 'ingredients', 'user_id',\n",
       "       'contributor_id', 'review_date', 'review', 'recipe_date', 'tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Framing Question\n",
    "We know that Recipe's mean TFIDF distribution is different for higher rating recipe than lower rating recipe:\n",
    "- We need `X` and a `y` -> find relationships! -> Supervised ML model\n",
    "- We currently have the DataFrame grouped by recipe\n",
    "- We want to predict `rating` as a classfication problem\n",
    "    - `rating` in recipe df: a quality of recipe\n",
    "    - `rating` in user_id df: user preference ✅\n",
    "- Features for user_id df:\n",
    "    - `TF-IDF mean/max/sum/partial_mean` of `description` for **recipe per user_id** (may have more than one recipe) that have **high ratings**\n",
    "        - This evaluates whether a word shows more often in this **user's high rated recipe decription** compare to all **recipe decription**, thus, meaning that it is more important to this user.\n",
    "    - `n_ingredients`\n",
    "    - `n_steps`\n",
    "    - `minutes`\n",
    "    - `calories`\n",
    "    - `sodium`\n",
    "    - `previous_rating` (need to explore)\n",
    "    - `word2vec` (need to explore, somr info [here](https://towardsdatascience.com/word2vec-explained-49c52b4ccb71)) \n",
    "        - Each `user_id` have a pool of words in a **vector space** (from description, can have more)\n",
    "        - We want to see how similar (cosine distance) between recipe tags `word2vec` and the pool\n",
    "        - [good theory background](https://medium.com/@zafaralibagh6/a-simple-word2vec-tutorial-61e64e38a6a1)\n",
    "\n",
    "- consider using `tags`, `review`, `steps`?\n",
    "\n",
    "- Further: using preference to recomand recipe!\n",
    "\n",
    "- `Voting`?\n",
    "\n",
    "- [Gaussian Bayesian Network](https://scikit-learn.org/stable/modules/naive_bayes.html)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "### Baseline Model\n",
    "**Analysis**:\n",
    "Train a “baseline model” for your prediction task that uses at least two features. (For this requirement, two features means selecting at least two columns from your original dataset that you should transform). You can leave numerical features as-is, but you’ll need to take care of categorical columns using an appropriate encoding. Implement all steps (feature transforms and model training) in a single sklearn Pipeline.\n",
    "\n",
    "Note: Both now and in Step 7: Final Model, make sure to evaluate your model’s ability to generalize to unseen data!\n",
    "\n",
    "There is no “required” performance metric that your baseline model needs to achieve.\n",
    "\n",
    "**Report**:\n",
    "Describe your model and state the features in your model, including how many are quantitative, ordinal, and nominal, and how you performed any necessary encodings. Report the performance of your model and whether or not you believe your current model is “good” and why.\n",
    "\n",
    "Tip: Make sure to hit all of the points above: many projects in the past have lost points for not doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "### Predictive Question\n",
    "We want to predict `rating` as a classfication problem, prdicting `rating` (5 catagories) in the user_id DataFrame to demonstarte understanding of user preference.\n",
    "- Using the original big DataFrame for predicting rating\n",
    "\n",
    "### Feature Engineering\n",
    "Remanber to take care of the missing data\n",
    "\n",
    "**Feature Direct Usage**\n",
    "- `n_ingredients`\n",
    "- `n_steps`\n",
    "- `minutes`\n",
    "- `calories`\n",
    "- `sodium`\n",
    "\n",
    "**Feature Engineering**\n",
    "- `tfidf_10_partial_mean` of `description` for **recipe per user_id** (may have more than one recipe) that have **high ratings**\n",
    "    - This evaluates whether a word shows more often in this **user's high rated recipe decription** compare to all **recipe decription**, thus, meaning that it is more important to this user.\n",
    "- `Word2Vec` Similarity\n",
    "    - All good `recipe` (above 3 rating) can be a pool of words in a **vector space** (from description, can have more)\n",
    "    - We want to see how similar (cosine distance) between each recipe `word2vec` description's vector to the good pool of vectors\n",
    "\n",
    "### Ensemble Learning (Bagging, Stacking, Boosting)\n",
    "Heterogenous Ensemble Voting:\n",
    "1. Homogenous Ensemble `Rabndom Forest`\n",
    "2. Model2...\n",
    "3. Model3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         these are the most; chocolatey, moist, rich, d...\n",
       "1         this is the recipe that we use at my school ca...\n",
       "2         since there are already 411 recipes for brocco...\n",
       "                                ...                        \n",
       "234426    i've heard of the 'cookies by design' company,...\n",
       "234427    i've heard of the 'cookies by design' company,...\n",
       "234428    i've heard of the 'cookies by design' company,...\n",
       "Name: description, Length: 234429, dtype: object"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = (step0.pipe(initial).pipe(transform_df))\n",
    "base_df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>recipe_date</th>\n",
       "      <th>...</th>\n",
       "      <th>sodium</th>\n",
       "      <th>protein</th>\n",
       "      <th>sat_fat</th>\n",
       "      <th>carbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 brownies in the world    best ever</td>\n",
       "      <td>40</td>\n",
       "      <td>985201</td>\n",
       "      <td>2008-10-27</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 in canada chocolate chip cookies</td>\n",
       "      <td>45</td>\n",
       "      <td>1848091</td>\n",
       "      <td>2011-04-11</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412 broccoli casserole</td>\n",
       "      <td>40</td>\n",
       "      <td>50969</td>\n",
       "      <td>2008-05-30</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234426</th>\n",
       "      <td>cookies by design   sugar shortbread cookies</td>\n",
       "      <td>20</td>\n",
       "      <td>506822</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234427</th>\n",
       "      <td>cookies by design   sugar shortbread cookies</td>\n",
       "      <td>20</td>\n",
       "      <td>506822</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234428</th>\n",
       "      <td>cookies by design   sugar shortbread cookies</td>\n",
       "      <td>20</td>\n",
       "      <td>506822</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234429 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  minutes contributor_id  \\\n",
       "0               1 brownies in the world    best ever       40         985201   \n",
       "1                 1 in canada chocolate chip cookies       45        1848091   \n",
       "2                             412 broccoli casserole       40          50969   \n",
       "...                                              ...      ...            ...   \n",
       "234426  cookies by design   sugar shortbread cookies       20         506822   \n",
       "234427  cookies by design   sugar shortbread cookies       20         506822   \n",
       "234428  cookies by design   sugar shortbread cookies       20         506822   \n",
       "\n",
       "       recipe_date  ... sodium  protein sat_fat carbs  \n",
       "0       2008-10-27  ...    3.0      3.0    19.0   6.0  \n",
       "1       2011-04-11  ...   22.0     13.0    51.0  26.0  \n",
       "2       2008-05-30  ...   32.0     22.0    36.0   3.0  \n",
       "...            ...  ...    ...      ...     ...   ...  \n",
       "234426  2008-04-15  ...    4.0      4.0    11.0   6.0  \n",
       "234427  2008-04-15  ...    4.0      4.0    11.0   6.0  \n",
       "234428  2008-04-15  ...    4.0      4.0    11.0   6.0  \n",
       "\n",
       "[234429 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_df(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minutes</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review</th>\n",
       "      <th>recipe_date</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipe_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275022.0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[2008-04-07 00:00:00, 2013-06-07 00:00:00, 201...</td>\n",
       "      <td>[Easy comfort food! I definitely thought it wa...</td>\n",
       "      <td>[2008-01-01 00:00:00, 2008-01-01 00:00:00, 200...</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275024.0</th>\n",
       "      <td>55.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[2009-05-26 00:00:00]</td>\n",
       "      <td>[When I found myself needing a dessert and hav...</td>\n",
       "      <td>[2008-01-01 00:00:00]</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275026.0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[2013-09-21 00:00:00, 2013-12-17 00:00:00]</td>\n",
       "      <td>[Sorry, this one didn&amp;#039;t work out so well....</td>\n",
       "      <td>[2008-01-01 00:00:00, 2008-01-01 00:00:00]</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537543.0</th>\n",
       "      <td>55.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[2018-12-15 00:00:00]</td>\n",
       "      <td>[I Didn't see pumpkin puree in ingredients jus...</td>\n",
       "      <td>[2018-11-16 00:00:00]</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, cui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537671.0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[2018-12-15 00:00:00]</td>\n",
       "      <td>[These are an absolute work of art, but just t...</td>\n",
       "      <td>[2018-11-28 00:00:00]</td>\n",
       "      <td>[time-to-make, course, preparation, occasion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537716.0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[2018-12-06 00:00:00]</td>\n",
       "      <td>[These were the best game day sandwiches. I co...</td>\n",
       "      <td>[2018-12-04 00:00:00]</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83781 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           minutes  n_steps  n_ingredients  avg_rating  ...  \\\n",
       "recipe_id                                               ...   \n",
       "275022.0      50.0     11.0            7.0         3.0  ...   \n",
       "275024.0      55.0      6.0            8.0         3.0  ...   \n",
       "275026.0      45.0      7.0            9.0         3.0  ...   \n",
       "...            ...      ...            ...         ...  ...   \n",
       "537543.0      55.0      8.0           10.0         NaN  ...   \n",
       "537671.0     135.0     54.0           12.0         NaN  ...   \n",
       "537716.0      40.0     12.0           13.0         5.0  ...   \n",
       "\n",
       "                                                 review_date  \\\n",
       "recipe_id                                                      \n",
       "275022.0   [2008-04-07 00:00:00, 2013-06-07 00:00:00, 201...   \n",
       "275024.0                               [2009-05-26 00:00:00]   \n",
       "275026.0          [2013-09-21 00:00:00, 2013-12-17 00:00:00]   \n",
       "...                                                      ...   \n",
       "537543.0                               [2018-12-15 00:00:00]   \n",
       "537671.0                               [2018-12-15 00:00:00]   \n",
       "537716.0                               [2018-12-06 00:00:00]   \n",
       "\n",
       "                                                      review  \\\n",
       "recipe_id                                                      \n",
       "275022.0   [Easy comfort food! I definitely thought it wa...   \n",
       "275024.0   [When I found myself needing a dessert and hav...   \n",
       "275026.0   [Sorry, this one didn&#039;t work out so well....   \n",
       "...                                                      ...   \n",
       "537543.0   [I Didn't see pumpkin puree in ingredients jus...   \n",
       "537671.0   [These are an absolute work of art, but just t...   \n",
       "537716.0   [These were the best game day sandwiches. I co...   \n",
       "\n",
       "                                                 recipe_date  \\\n",
       "recipe_id                                                      \n",
       "275022.0   [2008-01-01 00:00:00, 2008-01-01 00:00:00, 200...   \n",
       "275024.0                               [2008-01-01 00:00:00]   \n",
       "275026.0          [2008-01-01 00:00:00, 2008-01-01 00:00:00]   \n",
       "...                                                      ...   \n",
       "537543.0                               [2018-11-16 00:00:00]   \n",
       "537671.0                               [2018-11-28 00:00:00]   \n",
       "537716.0                               [2018-12-04 00:00:00]   \n",
       "\n",
       "                                                        tags  \n",
       "recipe_id                                                     \n",
       "275022.0   [60-minutes-or-less, time-to-make, course, mai...  \n",
       "275024.0   [60-minutes-or-less, time-to-make, course, pre...  \n",
       "275026.0   [60-minutes-or-less, time-to-make, course, mai...  \n",
       "...                                                      ...  \n",
       "537543.0   [60-minutes-or-less, time-to-make, course, cui...  \n",
       "537671.0   [time-to-make, course, preparation, occasion, ...  \n",
       "537716.0   [60-minutes-or-less, time-to-make, course, mai...  \n",
       "\n",
       "[83781 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_df(df_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_high_score_corpus = df_recipe[df_recipe['rating']>=3]['description'].astype(str).str.split(' ').to_list()\n",
    "full_training_corpus = word_tokenize(' '.join(df_recipe[df_recipe['rating']>=3]['description'].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a feature model\n",
    "word_vec = Word2Vec(recipe_high_score_corpus, window=7, sg=1, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_df['description'].apply(lambda x: [word_vec.wv[word] for word in x if word in full_training_corpus.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_words = base_df['description'].astype(str).apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [these, are, the, most, ;, chocolatey, ,, mois...\n",
       "1         [this, is, the, recipe, that, we, use, at, my,...\n",
       "2         [since, there, are, already, 411, recipes, for...\n",
       "                                ...                        \n",
       "234426    [i, 've, heard, of, the, 'cookies, by, design,...\n",
       "234427    [i, 've, heard, of, the, 'cookies, by, design,...\n",
       "234428    [i, 've, heard, of, the, 'cookies, by, design,...\n",
       "Name: description, Length: 234429, dtype: object"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_num = check_words.apply(lambda x: [word_vec.wv[word] for word in x if word in word_vec.wv.key_to_index.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [[-0.22415169, 0.14288595, -0.115010485, -0.15...\n",
       "1         [[-0.12147238, 0.22682993, 0.121205576, -0.404...\n",
       "2         [[0.19034623, -0.16149454, 0.32498103, 0.01796...\n",
       "                                ...                        \n",
       "234426    [[-0.023993827, 0.05469277, 0.16401625, -0.150...\n",
       "234427    [[-0.023993827, 0.05469277, 0.16401625, -0.150...\n",
       "234428    [[-0.023993827, 0.05469277, 0.16401625, -0.150...\n",
       "Name: description, Length: 234429, dtype: object"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sample = np.random.choice(list(word_vec.wv.key_to_index.keys()), 1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['shortbread', 'honeycrisp', 'combinations,', ..., 'states.',\n",
       "       'plum', 'mugs'], dtype='<U51')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similar(list):\n",
    "    avg_similarities = []\n",
    "    for word in list:\n",
    "        similarities = [word_vec.wv.similarity(word, vocab_word) for vocab_word in vocab_sample if word in word_vec.wv.key_to_index.keys()]\n",
    "        avg_similarities.append(np.mean(similarities))\n",
    "    \n",
    "    return pd.Series(avg_similarities).fillna(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_words.apply(lambda x: calculate_similar(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
