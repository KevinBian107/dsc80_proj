{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framing Prediction Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "from utils.eda import *\n",
    "from utils.dsc80_utils import *\n",
    "from utils.graph import *\n",
    "from utils.model import *\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, Binarizer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Problem Identification\n",
    "***\n",
    "\n",
    "**Analysis**:\n",
    "Identify a prediction problem. Feel free to use one of the example prediction problems stated in the “Example Questions and Prediction Problems” section of your dataset’s description page or pose a hypothesis test of your own. The prediction problem you come up with doesn’t have to be related to the question you were answering in Steps 1-4, but ideally, your entire project has some sort of coherent theme.\n",
    "\n",
    "**Report**:\n",
    "Clearly state your prediction problem and type (classification or regression). If you are building a classifier, make sure to state whether you are performing binary classification or multiclass classification. Report the response variable (i.e. the variable you are predicting) and why you chose it, the metric you are using to evaluate your model and why you chose it over other suitable metrics (e.g. accuracy vs. F1-score).\n",
    "\n",
    "Note: Make sure to justify what information you would know at the “time of prediction” and to only train your model using those features. For instance, if we wanted to predict your final exam grade, we couldn’t use your Project 4 grade, because Project 4 is only due after the final exam! Feel free to ask questions if you’re not sure.\n",
    "\n",
    "### Some Potential Ideas:\n",
    "1. Sentiment Analysis with `review` column\n",
    "2. Using   `recipe` column and feature engineering (length of `recipe`, TF-IDF, ...) to predict `ratings`\n",
    "3. Using text data as a input to predict the rating of the user and identify preference of users (pre-step to reconmender system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Framing a Question (Some Ideas)\n",
    "***\n",
    "\n",
    "We know that Recipe's mean TFIDF distribution is different for higher rating recipe than lower rating recipe:\n",
    "- We need `X` and a `y` -> find relationships! -> Supervised ML model\n",
    "- We currently have the DataFrame grouped by recipe\n",
    "- We want to predict `rating` as a classfication problem\n",
    "    - `rating` in recipe df: a quality of recipe\n",
    "    - `rating` in user_id df: user preference ✅\n",
    "- Features for user_id df:\n",
    "    - `TF-IDF mean/max/sum/partial_mean` of `description` for **recipe per user_id** (may have more than one recipe) that have **high ratings**\n",
    "        - This evaluates whether a word shows more often in this **user's high rated recipe decription** compare to all **recipe decription**, thus, meaning that it is more important to this user.\n",
    "    - `n_ingredients`\n",
    "    - `n_steps`\n",
    "    - `minutes`\n",
    "    - `calories`\n",
    "    - `sodium`\n",
    "    - `previous_rating` (need to explore)\n",
    "    - `word2vec` (need to explore, somr info [here](https://towardsdatascience.com/word2vec-explained-49c52b4ccb71)) \n",
    "        - Each `user_id` have a pool of words in a **vector space** (from description, can have more)\n",
    "        - We want to see how similar (cosine distance) between recipe tags `word2vec` and the pool\n",
    "        - [good theory background](https://medium.com/@zafaralibagh6/a-simple-word2vec-tutorial-61e64e38a6a1)\n",
    "\n",
    "- consider using `tags`, `review`, `steps`?\n",
    "\n",
    "- Further: using preference to recomand recipe!\n",
    "\n",
    "- `Voting`?\n",
    "\n",
    "- [Gaussian Bayesian Network](https://scikit-learn.org/stable/modules/naive_bayes.html)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Baseline Model\n",
    "***\n",
    "\n",
    "### Baseline Model\n",
    "**Analysis**:\n",
    "Train a “baseline model” for your prediction task that uses at least two features. (For this requirement, two features means selecting at least two columns from your original dataset that you should transform). You can leave numerical features as-is, but you’ll need to take care of categorical columns using an appropriate encoding. Implement all steps (feature transforms and model training) in a single sklearn Pipeline.\n",
    "\n",
    "Note: Both now and in Step 7: Final Model, make sure to evaluate your model’s ability to generalize to unseen data!\n",
    "\n",
    "There is no “required” performance metric that your baseline model needs to achieve.\n",
    "\n",
    "**Report**:\n",
    "Describe your model and state the features in your model, including how many are quantitative, ordinal, and nominal, and how you performed any necessary encodings. Report the performance of your model and whether or not you believe your current model is “good” and why.\n",
    "\n",
    "Tip: Make sure to hit all of the points above: many projects in the past have lost points for not doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Question\n",
    "We want to predict `rating` as a classfication problem, prdicting `rating` (5 catagories) in the user_id DataFrame to demonstarte understanding of user preference.\n",
    "- **Using the original big DataFrame for predicting rating**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Remanber to take care of the missing data\n",
    "\n",
    "- `n_ingredients`\n",
    "- `n_steps`\n",
    "- `minutes`\n",
    "- `calories`\n",
    "- `sodium`\n",
    "\n",
    "- `tfidf_mean` of `description` for **recipe per user_id** (may have more than one recipe)\n",
    "    - `TFIDF` of a word evaluates whether a word shows more often in this **user's recipe decription** compare to all **recipe decription**, thus, meaning that it is more important to this user.\n",
    "    - `TFIDF mean` for an `description` for the `recipe` represents the importantness of an sentence in the whole data set of text\n",
    "- `word2vec` Similarity\n",
    "    - All good `recipe` (above 3 rating) can be a pool of words in a **vector space** (from description, can have more)\n",
    "    - We want to see how similar (cosine distance) between each recipe `word2vec` description's vector to the good pool of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning (Bagging, Stacking, Boosting)\n",
    "Heterogenous Ensemble Voting:\n",
    "1. Homogenous Ensemble `Rabndom Forest`\n",
    "2. Model2...\n",
    "3. Model3..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Pipeline Creation\n",
    "***\n",
    "\n",
    "You can do all the function transfromation in here actually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.read_csv('food_data/RAW_interactions.csv')\n",
    "recipes = pd.read_csv('food_data/RAW_recipes.csv')\n",
    "step0 = recipes.merge(interactions, how='left', left_on='id', right_on='recipe_id', indicator=True)\n",
    "base_df = (step0\n",
    "           .pipe(initial)\n",
    "           .pipe(transform_df)\n",
    "           .pipe(outlier)\n",
    "           )[['n_ingredients','minutes','n_steps','description','sugar','calories','sodium','rating','tags']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "It have been shwon earlier that the missingness of the `rating` columns seems to be **NMAR**, so it is not dependent on the column but rather depending on itself. Thus, we will be imputing the ratings through **random imputation**.\n",
    "- Consider this a bit more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_impute(s):\n",
    "    s = s.copy()\n",
    "    num_null = s.isna().sum()\n",
    "    fill_values = np.random.choice(s.dropna(), num_null)\n",
    "    s[s.isna()] = fill_values\n",
    "    return s\n",
    "\n",
    "base_df['rating'] = prob_impute(base_df['rating'])\n",
    "base_df = base_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = base_df.assign(is_low = base_df['rating']<=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_df.drop('rating', axis=1)\n",
    "y = base_df['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isna().sum() + X_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_tfidf_max(df):\n",
    "#     from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#     lst = df['description'].explode().astype(str).values\n",
    "#     count = TfidfVectorizer()\n",
    "#     count.fit(lst)\n",
    "\n",
    "#     tfidf = pd.DataFrame(count.transform(lst).toarray(),\n",
    "#                             columns=count.get_feature_names_out())\n",
    "\n",
    "#     return df.reset_index().assign(max = tfidf.max(axis=1)).groupby('index').sum()\n",
    "\n",
    "\n",
    "def detect_key_low(df):\n",
    "    '''transforming description's tfidf to actual most important word in a description then compare if it is in the low rated set'''\n",
    "\n",
    "    def key_largest(row):\n",
    "        return row.index[row.argmax()]\n",
    "\n",
    "    def make_tfidf(series):\n",
    "        lst = series.explode().astype(str).values # this may be slow\n",
    "        count = TfidfVectorizer()\n",
    "        count.fit(lst)\n",
    "        return pd.DataFrame(count.transform(lst).toarray(), columns=count.get_feature_names_out())\n",
    "    \n",
    "    tfidf_low = make_tfidf(df[df['is_low']==True]['description'])\n",
    "    tfidf_base = make_tfidf(df['description'])\n",
    "\n",
    "    keyword_all = tfidf_base.apply(key_largest, axis=1) #argmax a bit faster\n",
    "    keyword_low = tfidf_low.apply(key_largest, axis=1)\n",
    "    pool_low = keyword_low.unique()\n",
    "\n",
    "    in_low = keyword_all.apply(lambda x: True if x in pool_low else False)\n",
    "\n",
    "    return pd.DataFrame(in_low)\n",
    "\n",
    "\n",
    "def tag_counts(df):\n",
    "    '''number of tags counted'''\n",
    "    return pd.DataFrame(df['tags'].apply(lambda x: len(x)).rename('counts'))\n",
    "\n",
    "\n",
    "def tag_ohe_pca(df):\n",
    "    '''OHE all the tag result after it have being pca dimension reduced to 50'''\n",
    "    # getting all the unique one quick\n",
    "    set = [j for i in df['tags'].tolist() for j in i] # explode in a time complexity efficient way\n",
    "    count = CountVectorizer()\n",
    "    count.fit(set).transform(set)\n",
    "\n",
    "    my_dict = np.array(list(count.vocabulary_.keys()))\n",
    "\n",
    "    def helper_function(list,dict):\n",
    "        return np.array([i in list for i in dict])\n",
    "\n",
    "    # helper_function(X_train[\"tags\"].iloc[0],my_dict)\n",
    "    \n",
    "    a = df[\"tags\"].apply(lambda x:helper_function(x, my_dict))\n",
    "    \n",
    "    # change array of array into 2D array\n",
    "    df_pca = pd.DataFrame(data = np.stack(a.to_numpy()),columns=my_dict)\n",
    "\n",
    "    # conduct PCA to reduce to just 50 dimensions\n",
    "    pca = PCA(n_components=50)\n",
    "    reduced = pca.fit_transform(df_pca)\n",
    "    \n",
    "    return reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `make_tfidf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_tfidf_max(X_train[['description']]).isna().sum() # no nan here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunctionTransformer(make_tfidf_max).fit_transform(X_train[['description']]).isna().sum() # no nan here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `count_tags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_counts(X_train[['tags']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `tag_ohe_pca`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[\"tags\"].apply(lambda x: x==np.array(list(count.vocabulary_.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_ohe_pca(X_train[['tags']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(pca_result)\n",
    "# len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `key_ohe`/`detect_key_low`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_low = detect_key_low(X_train[['is_low','description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is_low.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_relative = Pipeline([\n",
    "    ('bi_nsteps',Binarizer(threshold=25)),\n",
    "    ('norm_minutes_binary_nsteps', FunctionTransformer(lambda x: StdScalerByGroup().fit(x).transform(x))),\n",
    "])\n",
    "\n",
    "key_ohe = Pipeline([\n",
    "    ('tfidf',FunctionTransformer(detect_key_low)),\n",
    "    ('key_ohe', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "preproc_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf_key_ohe', key_ohe, ['is_low','description']),\n",
    "        ('bi_nsteps', Binarizer(threshold=25),['n_steps']),\n",
    "        ('bi_ningredients', Binarizer(threshold=20),['n_ingredients']),\n",
    "        ('norm_minutes_binary_nsteps',norm_relative,['n_steps','minutes']),\n",
    "        ('norm_minutes_binary_ningredients',norm_relative,['n_ingredients','minutes']),\n",
    "        ('tag_counts',FunctionTransformer(tag_counts),['tags']),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "preproc_lg = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tag_pca',FunctionTransformer(tag_ohe_pca),['tags']),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pl_rf = Pipeline([\n",
    "    ('preprocessor', preproc_rf),\n",
    "    ('rfc', RandomForestClassifier(max_depth=10,\n",
    "                                   n_estimators=100,\n",
    "                                   criterion='entropy',\n",
    "                                   min_samples_split=2,\n",
    "                                   ))\n",
    "])\n",
    "\n",
    "pl_lr = Pipeline([\n",
    "    ('preprocessor', preproc_lg),\n",
    "    ('lr',LogisticRegression(max_iter=500,\n",
    "                             multi_class='multinomial'))\n",
    "])\n",
    "\n",
    "voter = StackingClassifier(estimators=[('rfc', pl_rf), ('lr', pl_lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('tfidf_key_ohe',\n",
       "                                                  Pipeline(steps=[('tfidf',\n",
       "                                                                   FunctionTransformer(func=<function detect_key_low at 0x110b32af0>)),\n",
       "                                                                  ('key_ohe',\n",
       "                                                                   OneHotEncoder(drop='first'))]),\n",
       "                                                  ['is_low', 'description']),\n",
       "                                                 ('bi_nsteps',\n",
       "                                                  Binarizer(threshold=25),\n",
       "                                                  ['n_steps']),\n",
       "                                                 ('bi_ningredients',\n",
       "                                                  Binarizer(threshold=20),\n",
       "                                                  ['n_ingredients'])...\n",
       "                                                 ('norm_minutes_binary_ningredients',\n",
       "                                                  Pipeline(steps=[('bi_nsteps',\n",
       "                                                                   Binarizer(threshold=25)),\n",
       "                                                                  ('norm_minutes_binary_nsteps',\n",
       "                                                                   FunctionTransformer(func=<function <lambda> at 0x2d4bc1f70>))]),\n",
       "                                                  ['n_ingredients', 'minutes']),\n",
       "                                                 ('tag_counts',\n",
       "                                                  FunctionTransformer(func=<function tag_counts at 0x2c8a39ca0>),\n",
       "                                                  ['tags'])])),\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(criterion='entropy', max_depth=10))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7675459012154124"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pl_rf.predict(X_train) == y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "# hyperparameters = {\n",
    "# 'rfc__max_depth': np.arange(2, 20, 2),\n",
    "# 'rfc__min_samples_split': [2, 5, 10, 20],\n",
    "# 'rfc__criterion': ['gini', 'entropy'],\n",
    "# 'rfc__n_estimators': np.arange(100, 150, 10),\n",
    "# }\n",
    "# grids = GridSearchCV(pl_rf,\n",
    "#                      n_jobs=-1,\n",
    "#                      param_grid=hyperparameters,\n",
    "#                      return_train_score=False,\n",
    "#                      cv=5\n",
    "#                      )\n",
    "\n",
    "# grids.fit(X_train, y_train)\n",
    "# grids.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.737"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_sample = X_train.assign(rating=y_train).dropna().sample(1000)\n",
    "pl_rf.score(rand_sample.drop(columns='rating'), rand_sample['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $K$-fold Test Check With Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = X_train.assign(rating=y_train)\n",
    "# data_test[\"k_fold\"] = np.random.choice(list(range(5)),size = len(data_test))\n",
    "\n",
    "# total_train = []\n",
    "# total_test = []\n",
    "\n",
    "# for n in range(20):\n",
    "#     train_result = []\n",
    "#     test_result = []\n",
    "\n",
    "#     for i in range(5):\n",
    "#         data_test[\"k_fold\"] = np.random.choice(list(range(5)),size = len(data_test))\n",
    "\n",
    "#         test_data = data_test[data_test[\"k_fold\"]!=i].drop(columns=[\"k_fold\"])\n",
    "\n",
    "#         train_score = accuracy_score(voter.predict(data_test[data_test[\"k_fold\"]!=i].drop(columns=[\"rating\",\"k_fold\"])),\n",
    "#                                      data_test[data_test[\"k_fold\"]!=i][\"rating\"])\n",
    "        \n",
    "#         test_score = accuracy_score(voter.predict(data_test[data_test[\"k_fold\"]==i].drop(columns=[\"rating\",\"k_fold\"])),\n",
    "#                                data_test[data_test[\"k_fold\"]==i][\"rating\"])\n",
    "        \n",
    "#         test_result.append(test_score)\n",
    "#         train_result.append(train_score)\n",
    "    \n",
    "#     total_test.append(sum(test_result)/5)\n",
    "#     total_train.append(sum(train_result)/5)\n",
    "\n",
    "# print(f'Training: {sum([i > 0.75 for i in total_train])/20}')   \n",
    "# px.histogram(total_train).show()\n",
    "# print(f'Testing: {sum([i > 0.75 for i in total_test])/20}') \n",
    "# px.histogram(total_test).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
